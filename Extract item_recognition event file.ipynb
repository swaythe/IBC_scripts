{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'sub-11'\n",
    "battery = 'fbirn'\n",
    "task = 'item-recognition'\n",
    "\n",
    "main_dir = '/home/sshankar/ibc/analysis_pipeline/ibc_main/neurospin_data/info/'\n",
    "datadir = os.path.join(main_dir, sub, battery)\n",
    "os.chdir(datadir)\n",
    "csv_files = sorted(glob.glob('*' + task + '*.csv'))\n",
    "tsv_files = []\n",
    "# for i in range(len(csv_files)):\n",
    "i = 0\n",
    "tsv_files.append(task + '_' + sub + '_run-0' + str(i+1) + '.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.read_csv(os.path.join(datadir, csv_files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the csv file extracted from the E-Prime txt file, \n",
    "# run onset is the 'GetReady.OffsetTime' column of last row, \n",
    "# and all other columns of this row are empty.\n",
    "\n",
    "\n",
    "# if ses == 1:\n",
    "#     run_start = (file_df.loc[~np.isnan(file_df['Introduction.OffsetTime'])])['Introduction.OffsetTime']\n",
    "#     run_start = run_start.values[0]\n",
    "# else:\n",
    "#     run_start = file_df.loc[0]['blank.OnsetTime']\n",
    "\n",
    "run_start = (file_df.loc[~np.isnan(file_df['Introduction.OffsetTime'])])['Introduction.OffsetTime']\n",
    "run_start = run_start.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56621.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixation event durations in index numbers: 12, 8, 10, 6, 8, 10, 8, 6\n",
    "# There are always 14 probe items and 14 arrow trials\n",
    "\n",
    "fix_dur = [12, 8, 10, 6, 8, 10, 8, 6]\n",
    "task_dur = 14\n",
    "\n",
    "# Order of blocks in ses-01\n",
    "# fix, one, fix, three, fix, five, fix, arrows, fix, five, fix, one, fix, arrows, fix, three\n",
    "# Order of blocks in ses-02\n",
    "# fix, three, fix, five, fix, arrows, fix, one, fix, three, fix, one, fix, five, fix, arrows\n",
    "\n",
    "if i == 0:\n",
    "    blocks = ['fix', 'one', 'fix', 'three', 'fix', 'five', 'fix', 'arrows', \\\n",
    "              'fix', 'five', 'fix', 'one', 'fix', 'arrows', 'fix', 'three']\n",
    "else:\n",
    "    blocks = ['fix', 'three', 'fix', 'five', 'fix', 'arrows', 'fix', 'one', \\\n",
    "              'fix', 'three', 'fix', 'one', 'fix', 'five', 'fix', 'arrows']\n",
    "    \n",
    "tidx = 0\n",
    "trial_types = []\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for i, blk in enumerate(blocks):\n",
    "    if blk == 'one':\n",
    "        trial_types.append('load1_instr')\n",
    "        onsets.append(file_df.loc[tidx+15]['learnone.OnsetTime'])\n",
    "#         durations.append(file_df.loc[tidx]['learnone.OffsetTime']-file_df.loc[tidx+15]['learnone.OnsetTime'])\n",
    "        durations.append(2000)\n",
    "        \n",
    "        trial_types.append('encode1')\n",
    "        onsets.append(file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "#         durations.append(file_df.loc[tidx]['encodedigit.OffsetTime']-file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "        durations.append(1100)\n",
    "        \n",
    "        tidx = tidx + 1\n",
    "        \n",
    "        for pi in range(14):\n",
    "            if file_df.loc[tidx]['correctans'] == 'y':\n",
    "                trial_types.append('probe1_mem')\n",
    "            elif file_df.loc[tidx]['correctans'] == 'g':\n",
    "                trial_types.append('probe1_new')\n",
    "            else:\n",
    "                trial_types.append(file_df.loc[tidx]['correctans'])\n",
    "            onsets.append(file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx]['probedigit.OffsetTime']-file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        tidx = tidx + 1\n",
    "            \n",
    "    elif blk == 'three':\n",
    "        trial_types.append('load3_instr')\n",
    "        onsets.append(file_df.loc[tidx+17]['learnthree.OnsetTime'])\n",
    "#         durations.append(file_df.loc[tidx]['learnthree.OffsetTime']-file_df.loc[tidx+17]['learnthree.OnsetTime'])\n",
    "        durations.append(2000)\n",
    "        \n",
    "        for ei in range(3):\n",
    "            trial_types.append('encode3')\n",
    "            onsets.append(file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx+2]['encodedigit.OffsetTime']-file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        \n",
    "#         tidx = tidx + 3\n",
    "        \n",
    "        for pi in range(14):\n",
    "            if file_df.loc[tidx]['correctans'] == 'y':\n",
    "                trial_types.append('probe3_mem')\n",
    "            elif file_df.loc[tidx]['correctans'] == 'g':\n",
    "                trial_types.append('probe3_new')\n",
    "            else:\n",
    "                trial_types.append(file_df.loc[tidx]['correctans'])\n",
    "            onsets.append(file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx]['probedigit.OffsetTime']-file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        tidx = tidx + 1\n",
    "            \n",
    "    elif blk == 'five':\n",
    "        trial_types.append('load5_instr')\n",
    "        onsets.append(file_df.loc[tidx+19]['learnfive.OnsetTime'])\n",
    "#         durations.append(file_df.loc[tidx]['learnfive.OffsetTime']-file_df.loc[tidx+19]['learnfive.OnsetTime'])\n",
    "        durations.append(2000)\n",
    "        \n",
    "        for ei in range(5):\n",
    "            trial_types.append('encode5')\n",
    "            onsets.append(file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx+4]['encodedigit.OffsetTime']-file_df.loc[tidx]['encodedigit.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        \n",
    "#         tidx = tidx + 5\n",
    "        \n",
    "        for pi in range(14):\n",
    "            if file_df.loc[tidx]['correctans'] == 'y':\n",
    "                trial_types.append('probe3_mem')\n",
    "            elif file_df.loc[tidx]['correctans'] == 'g':\n",
    "                trial_types.append('probe3_new')\n",
    "            else:\n",
    "                trial_types.append(file_df.loc[tidx]['correctans'])\n",
    "            onsets.append(file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx]['probedigit.OffsetTime']-file_df.loc[tidx]['probedigit.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        tidx = tidx + 1\n",
    "\n",
    "    elif blk == 'arrows':\n",
    "        for pi in range(14):\n",
    "            if file_df.loc[tidx]['correctans'] == 'y':\n",
    "                trial_types.append('arrow_left')\n",
    "            elif file_df.loc[tidx]['correctans'] == 'g':\n",
    "                trial_types.append('arrow_right')\n",
    "            else:\n",
    "                trial_types.append(file_df.loc[tidx]['correctans'])\n",
    "            onsets.append(file_df.loc[tidx]['arrow.OnsetTime'])\n",
    "#             durations.append(file_df.loc[tidx]['arrow.OffsetTime']-file_df.loc[tidx]['arrow.OnsetTime'])\n",
    "            durations.append(1100)\n",
    "            tidx = tidx + 1\n",
    "        tidx = tidx + 1\n",
    "        \n",
    "    elif blk == 'fix':\n",
    "        ntr = fix_dur[int(i/2)]\n",
    "        trial_types.append('fix')\n",
    "        onsets.append(file_df.loc[tidx]['blank.OnsetTime'])\n",
    "        if file_df.loc[tidx+ntr-1]['Procedure'] == 'fixationon':\n",
    "            durations.append(file_df.loc[tidx+ntr-1]['cross.OnsetTime']+file_df.loc[tidx+ntr-1]['Duration'] \\\n",
    "                            - file_df.loc[tidx]['blank.OnsetTime'])\n",
    "        elif file_df.loc[tidx+ntr-1]['Procedure'] == 'fixationoff':\n",
    "            durations.append(file_df.loc[tidx+ntr-1]['blank.OnsetTime']+file_df.loc[tidx+ntr-1]['Duration'] \\\n",
    "                            - file_df.loc[tidx]['blank.OnsetTime'])\n",
    "        tidx = tidx + ntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to save to events file\n",
    "df = pd.DataFrame({'onset':np.array(onsets-run_start)/1000, 'duration':np.array(durations)/1000, 'trial_type':trial_types})\n",
    "df.to_csv(os.path.join(datadir, tsv_files[0]), sep='\\t', float_format='%0.3f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
