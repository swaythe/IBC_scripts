{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshankar/env/fastsrm/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker, MultiNiftiMasker\n",
    "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\n",
    "from fastsrm.fastsrm import FastSRM\n",
    "from fastsrm import fastsrm\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from nilearn.image import new_img_like\n",
    "import ibc_public\n",
    "import nibabel as nib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask image\n",
    "_package_directory = os.path.dirname(os.path.abspath(ibc_public.__file__))\n",
    "mask_gm = nib.load(os.path.join(_package_directory, '../ibc_data', 'gm_mask_3mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task of interest\n",
    "task = 'clips'\n",
    "\n",
    "# Any specific files that should be used for FastSRM\n",
    "if task == 'clips':\n",
    "    filepattern = '*Trn*.nii.gz'\n",
    "else:\n",
    "    filepattern = '*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for a previously unused atlas. \n",
    "# Else, you should have a .npy file saved from before, and you can just load it.\n",
    "# The transform() funtion takes a few minutes to run so don't run it \n",
    "# unless you absolutely need to.\n",
    "\n",
    "# Now, a bit of shape shifting to make the atlas compatible with\n",
    "# what fastsrm.reduce_data() requires.\n",
    "# 1. Add a 4th dimension to the 3D atlas. The 4th dimension will have as many\n",
    "#   elements as atlas parcesl (444, in this case)\n",
    "# 2. The 3D \"volume\" pertaining to each 4th dimension will contain 1 in the\n",
    "#   \"voxel\" for that parcel and 0 otherwise\n",
    "# 3. Apply the atlas masker set up previously to transform the new 4D atlas\n",
    "#   into 2D, with n_voxel rows and n_parcel columns,\n",
    "#   where n_voxel is the number of voxels in the transformed image matrix\n",
    "# 4. Reduce the 2D atlas matrix to 1D by using the argmax function along the\n",
    "#   column dimension. Now, the transformed atlas has n_voxel elements.\n",
    "\n",
    "atlas_loc = os.path.join('..', task, '3mm')\n",
    "if os.path.exists(os.path.join(atlas_loc, 'atlas_masked.npy')):\n",
    "    atlas = np.load(os.path.join(atlas_loc, 'atlas_masked.npy'), allow_pickle=True)\n",
    "else:\n",
    "    # Specify the atlas\n",
    "    basc444 = fetch_atlas_basc_multiscale_2015()['scale444']\n",
    "    basc_im = image.load_img(basc444).get_data()\n",
    "\n",
    "    atlas_masker = NiftiMasker(mask_img=mask_gm).fit()\n",
    "\n",
    "    if len(basc_im.shape) == 3:\n",
    "        n_components = len(np.unique(basc_im)) - 1\n",
    "        xa, ya, za = basc_im.shape\n",
    "        A = np.zeros((xa, ya, za, n_components + 1))\n",
    "        atlas = np.zeros((xa, ya, za, n_components + 1))\n",
    "        for c in np.unique(basc_im)[1:].astype(int):\n",
    "            X_ = np.copy(basc_im)\n",
    "            X_[X_ != c] = 0.\n",
    "            X_[X_ == c] = 1.\n",
    "            A[:, :, :, c] = X_\n",
    "        atlas = atlas_masker.transform(new_img_like(basc444, A))\n",
    "        atlas = np.argmax(atlas, axis=0)\n",
    "\n",
    "    # # Save the transformed atlas\n",
    "    np.save(os.path.join(atlas_loc, 'atlas_masked.npy'), atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to standardize (0 mean, 1 SD) the image files\n",
    "# and to transform them to a 2D array, as FastSRM requires\n",
    "img_masker = NiftiMasker(mask_img=mask_gm, \n",
    "                              standardize=True, \n",
    "                              smoothing_fwhm=5,\n",
    "                              detrend=True,\n",
    "                              high_pass=1./128,\n",
    "                              t_r=2.0).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a list of movie session files \n",
    "movie_dir = os.path.join('..', task, '3mm')\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "nsub = 0\n",
    "\n",
    "movie_arrays = []\n",
    "\n",
    "# Number of sessions per subject\n",
    "# Different tasks have different numbers of sessions.\n",
    "# Also, all subjects might not have completed all sessions.\n",
    "if task == 'clips':\n",
    "    # For the clips task, one subject doesn't have all 4 sessions, and\n",
    "    # FastSRM requires that all subjects have the same numbers of TRs\n",
    "    sessn = 3\n",
    "else:\n",
    "    sessn = 2\n",
    "\n",
    "# Create 2D masked arrays from image data and save to file for quick and easy access\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        nsub += 1\n",
    "        sess = sorted(glob.glob(sub + '/ses*'))\n",
    "        sidx = 0\n",
    "       \n",
    "        for i, ses in enumerate(sess):\n",
    "            if os.path.isdir(ses) and sidx < sessn:\n",
    "                sidx += 1\n",
    "                if os.path.exists(os.path.join(ses,'masked_imgs_preproc.npy')):\n",
    "                    masked_imgs = np.load(os.path.join(ses, 'masked_imgs_preproc.npy'), \n",
    "                                          allow_pickle=True)\n",
    "                else:    \n",
    "                    movie_imgs = sorted(glob.glob(ses + '/' + filepattern))\n",
    "                    masked_imgs = img_masker.transform(movie_imgs)\n",
    "                    np.save(os.path.join(ses, 'masked_imgs_preproc.npy'), masked_imgs)\n",
    "\n",
    "                movie_arrays.append(masked_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells test whether the timeseries add up to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 325, 46448)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.squeeze(masked_imgs[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 46448)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tc = np.mean(a,1)\n",
    "type(avg_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tc = avg_tc.reshape(len(avg_tc),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_dif = a - avg_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 46448)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the runs belonging to each subject, \n",
    "# and then create a list of lists with all subjects' data\n",
    "sub_movie = []\n",
    "# nsess = len(movie_arrays[0])\n",
    "for i in range(0, nsub*sessn, sessn):\n",
    "    part = []\n",
    "    for j in range(sessn):\n",
    "        # The inner concatenates create one list each for each session\n",
    "        # The outer concatenate creates one list with data from all runs\n",
    "        part.append(np.concatenate(movie_arrays[i+j]))\n",
    "    sub_movie.append(np.concatenate(part).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average timeseries and subtract it from the data. \n",
    "# We want the data to sum to zero in both the temporal and spatial domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the FastSRM model with the data\n",
    "fast_srm = FastSRM(\n",
    "    atlas=atlas,\n",
    "    n_components=20,\n",
    "    n_jobs=1,\n",
    "    n_iter=10,\n",
    "    temp_dir='/tmp',\n",
    "    low_ram=True, \n",
    "    aggregate=\"mean\" \n",
    ")\n",
    "fast_srm.fit(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure that the spatial maps sum to zero \n",
    "# (i.e., sum of all voxel values is 0)\n",
    "# Run CanICA on the spatial maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
