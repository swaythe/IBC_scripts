{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker, MultiNiftiMasker\n",
    "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\n",
    "from nilearn.image import new_img_like\n",
    "from fastsrm.fastsrm import FastSRM\n",
    "from nilearn import image, plotting\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import ibc_public\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask image\n",
    "_package_directory = os.path.dirname(os.path.abspath(ibc_public.__file__))\n",
    "mask_gm = nib.load(os.path.join(_package_directory, '../ibc_data', 'gm_mask_3mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task of interest\n",
    "task = 'raiders'\n",
    "\n",
    "# Any specific files that should be used for FastSRM\n",
    "if task == 'clips':\n",
    "    sessn = 3\n",
    "    filepattern = '*Trn*.nii.gz'\n",
    "else:\n",
    "    sessn = 2\n",
    "    filepattern = '*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for a previously unused atlas. \n",
    "# Else, you should have a .npy file saved from before, and you can just load it.\n",
    "# The transform() funtion takes a few minutes to run so don't run it \n",
    "# unless you absolutely need to.\n",
    "\n",
    "# Now, a bit of shape shifting to make the atlas compatible with\n",
    "# what fastsrm.reduce_data() requires.\n",
    "# 1. Add a 4th dimension to the 3D atlas. The 4th dimension will have as many\n",
    "#   elements as atlas parcesl (444, in this case)\n",
    "# 2. The 3D \"volume\" pertaining to each 4th dimension will contain 1 in the\n",
    "#   \"voxel\" for that parcel and 0 otherwise\n",
    "# 3. Apply the atlas masker set up previously to transform the new 4D atlas\n",
    "#   into 2D, with n_voxel rows and n_parcel columns,\n",
    "#   where n_voxel is the number of voxels in the transformed image matrix\n",
    "# 4. Reduce the 2D atlas matrix to 1D by using the argmax function along the\n",
    "#   column dimension. Now, the transformed atlas has n_voxel elements.\n",
    "\n",
    "atlas_loc = os.path.join('..', task, '3mm')\n",
    "if os.path.exists(os.path.join(atlas_loc, 'atlas_masked.npy')):\n",
    "    atlas = np.load(os.path.join(atlas_loc, 'atlas_masked.npy'), allow_pickle=True)\n",
    "else:\n",
    "    # Specify the atlas\n",
    "    basc444 = fetch_atlas_basc_multiscale_2015()['scale444']\n",
    "    basc_im = image.load_img(basc444).get_data()\n",
    "\n",
    "    atlas_masker = NiftiMasker(mask_img=mask_gm).fit()\n",
    "\n",
    "    if len(basc_im.shape) == 3:\n",
    "        n_components = len(np.unique(basc_im)) - 1\n",
    "        xa, ya, za = basc_im.shape\n",
    "        A = np.zeros((xa, ya, za, n_components + 1))\n",
    "        atlas = np.zeros((xa, ya, za, n_components + 1))\n",
    "        for c in np.unique(basc_im)[1:].astype(int):\n",
    "            X_ = np.copy(basc_im)\n",
    "            X_[X_ != c] = 0.\n",
    "            X_[X_ == c] = 1.\n",
    "            A[:, :, :, c] = X_\n",
    "        atlas = atlas_masker.transform(new_img_like(basc444, A))\n",
    "        atlas = np.argmax(atlas, axis=0)\n",
    "\n",
    "    # # Save the transformed atlas\n",
    "    np.save(os.path.join(atlas_loc, 'atlas_masked.npy'), atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to standardize (0 mean, 1 SD) the image files\n",
    "# and to transform them to a 2D array, as FastSRM requires\n",
    "img_masker = NiftiMasker(mask_img=mask_gm, \n",
    "                              standardize=True, \n",
    "                              smoothing_fwhm=5,\n",
    "                              detrend=True,\n",
    "                              high_pass=1./128,\n",
    "                              t_r=2.0).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now create a list of movie session files \n",
    "movie_dir = os.path.join('..', task, '3mm/')\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "nsub = 0\n",
    "\n",
    "movie_arrays = []\n",
    "\n",
    "# Number of sessions per subject\n",
    "# Different tasks have different numbers of sessions.\n",
    "# Also, all subjects might not have completed all sessions.\n",
    "if task == 'clips':\n",
    "    # For the clips task, one subject doesn't have all 4 sessions, and\n",
    "    # FastSRM requires that all subjects have the same numbers of TRs\n",
    "    sessn = 3\n",
    "else:\n",
    "    sessn = 2\n",
    "\n",
    "# Create 2D masked arrays from image data and save to file for quick and easy access\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        nsub += 1\n",
    "        sess = sorted(glob.glob(sub + '/ses*'))\n",
    "       \n",
    "        for i, ses in enumerate(sess):\n",
    "            if os.path.isdir(ses) and i < sessn:\n",
    "                if os.path.exists(os.path.join(ses,'masked_imgs_preproc.npy')):\n",
    "                    masked_imgs = np.load(os.path.join(ses, 'masked_imgs_preproc.npy'), \n",
    "                                          allow_pickle=True)\n",
    "                else:    \n",
    "                    movie_imgs = sorted(glob.glob(ses + '/' + filepattern))\n",
    "                    masked_imgs = img_masker.transform(movie_imgs)\n",
    "                    np.save(os.path.join(ses, 'masked_imgs_preproc.npy'), masked_imgs)\n",
    "\n",
    "                movie_arrays.append(masked_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the runs belonging to each subject, \n",
    "# and then create a list of lists with all subjects' data\n",
    "sub_movie = []\n",
    "# nsess = len(movie_arrays[0])\n",
    "for i in range(0, nsub*sessn, sessn):\n",
    "    part = []\n",
    "    for j in range(sessn):\n",
    "        # The inner concatenates create one list each for each session\n",
    "        # The outer concatenate creates one list with data from all runs\n",
    "        part.append(np.concatenate(movie_arrays[i+j]))\n",
    "    sub_movie.append(np.concatenate(part).T)\n",
    "#         sub_movie.append(np.concatenate((np.concatenate(movie_arrays[i]), np.concatenate(movie_arrays[i+1]))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the FastSRM model with the data\n",
    "fast_srm = FastSRM(\n",
    "    atlas=atlas,\n",
    "    n_components=20,\n",
    "    n_jobs=1,\n",
    "    n_iter=10,\n",
    "    temp_dir='/tmp',\n",
    "    low_ram=True, \n",
    "    aggregate=\"mean\",\n",
    ")\n",
    "fast_srm.fit(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the shared temporal responses of subjects\n",
    "shared_resp = fast_srm.transform(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the shared response vector for future use\n",
    "fastsrm_dir = os.path.join(movie_dir, 'fastsrm')\n",
    "if not os.path.isdir(fastsrm_dir):\n",
    "    os.mkdir(fastsrm_dir)\n",
    "\n",
    "np.save(os.path.join(fastsrm_dir, 'shared_resp.npy'), shared_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the shared responses look like\n",
    "fig, axs = plt.subplots(20, sharex=True, sharey=True, \n",
    "                        figsize=(10,50))\n",
    "# gridspec_kw={'hspace': 0.2}\n",
    "for i in range(len(shared_resp)):\n",
    "    axs[i].plot(shared_resp[i,:])\n",
    "    axs[i].set_title('Shared response #' + str(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(fastsrm_dir, 'shared_resp.pdf'), format='pdf', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for one subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_9.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for a different subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_5.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the basis lists to subject folders for posterity\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    srm_sub_dir = os.path.join(sub, 'ident_fastsrm')\n",
    "    if not os.path.isdir(srm_sub_dir):\n",
    "        os.mkdir(srm_sub_dir)\n",
    "    copyfile(fast_srm.basis_list[s], os.path.join(srm_sub_dir, 'basis_list.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the basis lists into their components and save them as \n",
    "# niimg-like files to use in other nistats/nilearn functions\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    bls = np.load(os.path.join(sub, 'ident_fastsrm', 'basis_list.npy'))\n",
    "    for i in range(20):\n",
    "        nib.save(img_masker.inverse_transform(bls[i]), \n",
    "                 os.path.join(sub, 'ident_fastsrm', 'basis_list-' + str(i).zfill(2) + '.nii.gz'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
