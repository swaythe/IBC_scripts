{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshankar/env/fastsrm/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker, MultiNiftiMasker\n",
    "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\n",
    "from fastsrm.fastsrm import FastSRM\n",
    "from fastsrm import fastsrm\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from nilearn.image import new_img_like\n",
    "import ibc_public\n",
    "import nibabel as nib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask image\n",
    "_package_directory = os.path.dirname(os.path.abspath(ibc_public.__file__))\n",
    "mask_gm = nib.load(os.path.join(_package_directory, '../ibc_data', 'gm_mask_3mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task of interest\n",
    "task = 'raiders'\n",
    "\n",
    "# Any specific files that should be used for FastSRM\n",
    "if task == 'clips':\n",
    "    filepattern = '*Trn*.nii.gz'\n",
    "else:\n",
    "    filepattern = '*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for a previously unused atlas. \n",
    "# Else, you should have a .npy file saved from before, and you can just load it.\n",
    "# The transform() funtion takes a few minutes to run so don't run it \n",
    "# unless you absolutely need to.\n",
    "\n",
    "# Now, a bit of shape shifting to make the atlas compatible with\n",
    "# what fastsrm.reduce_data() requires.\n",
    "# 1. Add a 4th dimension to the 3D atlas. The 4th dimension will have as many\n",
    "#   elements as atlas parcesl (444, in this case)\n",
    "# 2. The 3D \"volume\" pertaining to each 4th dimension will contain 1 in the\n",
    "#   \"voxel\" for that parcel and 0 otherwise\n",
    "# 3. Apply the atlas masker set up previously to transform the new 4D atlas\n",
    "#   into 2D, with n_voxel rows and n_parcel columns,\n",
    "#   where n_voxel is the number of voxels in the transformed image matrix\n",
    "# 4. Reduce the 2D atlas matrix to 1D by using the argmax function along the\n",
    "#   column dimension. Now, the transformed atlas has n_voxel elements.\n",
    "\n",
    "atlas_loc = os.path.join('..', task, '3mm')\n",
    "if os.path.exists(os.path.join(atlas_loc, 'atlas_masked.npy')):\n",
    "    atlas = np.load(os.path.join(atlas_loc, 'atlas_masked.npy'), allow_pickle=True)\n",
    "else:\n",
    "    # Specify the atlas\n",
    "    basc444 = fetch_atlas_basc_multiscale_2015()['scale444']\n",
    "    basc_im = image.load_img(basc444).get_data()\n",
    "\n",
    "    atlas_masker = NiftiMasker(mask_img=mask_gm).fit()\n",
    "\n",
    "    if len(basc_im.shape) == 3:\n",
    "        n_components = len(np.unique(basc_im)) - 1\n",
    "        xa, ya, za = basc_im.shape\n",
    "        A = np.zeros((xa, ya, za, n_components + 1))\n",
    "        atlas = np.zeros((xa, ya, za, n_components + 1))\n",
    "        for c in np.unique(basc_im)[1:].astype(int):\n",
    "            X_ = np.copy(basc_im)\n",
    "            X_[X_ != c] = 0.\n",
    "            X_[X_ == c] = 1.\n",
    "            A[:, :, :, c] = X_\n",
    "        atlas = atlas_masker.transform(new_img_like(basc444, A))\n",
    "        atlas = np.argmax(atlas, axis=0)\n",
    "\n",
    "    # # Save the transformed atlas\n",
    "    np.save(os.path.join(atlas_loc, 'atlas_masked.npy'), atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to standardize (0 mean, 1 SD) the image files\n",
    "# and to transform them to a 2D array, as FastSRM requires\n",
    "img_masker = NiftiMasker(mask_img=mask_gm, \n",
    "                              standardize=True, \n",
    "                              smoothing_fwhm=5,\n",
    "                              detrend=True,\n",
    "                              high_pass=1./128,\n",
    "                              t_r=2.0).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a list of movie session files \n",
    "movie_dir = os.path.join('..', task, '3mm')\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "nsub = 0\n",
    "\n",
    "movie_arrays = []\n",
    "\n",
    "# Number of sessions per subject\n",
    "# Different tasks have different numbers of sessions.\n",
    "# Also, all subjects might not have completed all sessions.\n",
    "if task == 'clips':\n",
    "    # For the clips task, one subject doesn't have all 4 sessions, and\n",
    "    # FastSRM requires that all subjects have the same numbers of TRs\n",
    "    sessn = 3\n",
    "else:\n",
    "    sessn = 2\n",
    "\n",
    "# Create 2D masked arrays from image data and save to file for quick and easy access\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        nsub += 1\n",
    "        sess = sorted(glob.glob(sub + '/ses*'))\n",
    "        sidx = 0\n",
    "       \n",
    "        for i, ses in enumerate(sess):\n",
    "            if os.path.isdir(ses) and sidx < sessn:\n",
    "                sidx += 1\n",
    "                if os.path.exists(os.path.join(ses,'masked_imgs_preproc.npy')):\n",
    "                    masked_imgs = np.load(os.path.join(ses, 'masked_imgs_preproc.npy'), \n",
    "                                          allow_pickle=True)\n",
    "                else:    \n",
    "                    movie_imgs = sorted(glob.glob(ses + '/' + filepattern))\n",
    "                    masked_imgs = img_masker.transform(movie_imgs)\n",
    "                    np.save(os.path.join(ses, 'masked_imgs_preproc.npy'), masked_imgs)\n",
    "\n",
    "                movie_arrays.append(masked_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the runs belonging to each subject, \n",
    "# and then create a list of lists with all subjects' data\n",
    "sub_movie = []\n",
    "# nsess = len(movie_arrays[0])\n",
    "for i in range(0, nsub*sessn, sessn):\n",
    "    part = []\n",
    "    for j in range(sessn):\n",
    "        # The inner concatenates create one list each for each session\n",
    "        # The outer concatenate creates one list with data from all runs\n",
    "        part.append(np.concatenate(movie_arrays[i+j]))\n",
    "    sub_movie.append(np.concatenate(part).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastSRM(aggregate='mean', atlas=array([333, 333, 190, ..., 112, 315, 315]),\n",
       "        low_ram=True, n_components=20, n_iter=10, n_jobs=1, seed=None,\n",
       "        temp_dir='/tmp/fastsrm0e8c3929-4c24-41c4-b837-72b735c7306a',\n",
       "        verbose='warn')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the FastSRM model with the data\n",
    "n_components = 20\n",
    "n_jobs = 1\n",
    "n_iter = 10\n",
    "temp_dir = '/tmp'\n",
    "low_ram = True\n",
    "aggregate = 'mean'\n",
    "\n",
    "fast_srm = FastSRM(\n",
    "    atlas=atlas,\n",
    "    n_components=n_components,\n",
    "    n_jobs=n_jobs,\n",
    "    n_iter=n_iter,\n",
    "    temp_dir=temp_dir,\n",
    "    low_ram=low_ram, \n",
    "    aggregate=aggregate \n",
    ")\n",
    "fast_srm.fit(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure that the spatial maps sum to zero \n",
    "# (i.e., sum of all voxel values is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_0.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_1.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_2.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_3.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_4.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_5.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_6.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_7.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_8.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_9.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_10.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_11.npy',\n",
       " '/tmp/fastsrmc39d920c-f0ba-4558-9f3f-3ddaecae11e2/basis_12.npy']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_srm.basis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.63759193783642"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load one of the basis lists to check if spatial maps sum to 0\n",
    "bl1 = np.load(fast_srm.basis_list[0])\n",
    "sum(bl1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They don't, so let us subtract the voxel mean\n",
    "bl1_avg = bl1[0]-np.mean(bl1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.768091725424142e-14"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bl1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 20\n",
    "n_voxel = len(atlas)\n",
    "\n",
    "# Create a list of basis lists such that the resulting matrix\n",
    "# is n_components x (n_voxel * n_subjects) big. This matrix will\n",
    "# be the input to the spatial ICA.\n",
    "# Also, the spatial maps should sum to zero.\n",
    "\n",
    "bls = []\n",
    "\n",
    "for s in range(nsub):\n",
    "    bl_sub = np.zeros((n_components, n_voxel))\n",
    "    bl = np.load(fast_srm.basis_list[s])\n",
    "    for i in range(n_components):\n",
    "        bl_sub[i] = bl[i] - np.mean(bl[i])\n",
    "    bls.append(bl_sub)\n",
    "    \n",
    "basis_lists = np.concatenate(bls, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CanICA on the spatial maps\n",
    "from nilearn.decomposition import CanICA\n",
    "can_ica = CanICA(mask=mask_gm,\n",
    "                 n_components=n_components,\n",
    "                 standardize=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying CanICA with basis_lists as input. I get an error\n",
    "# because CanICA requires niimg-like objects as input.\n",
    "can_ica_comp = can_ica.fit(basis_lists.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, CanICA wants list of Niimg-like objects, not 2D arrays\n",
    "# Let's collect the list of basis-list nii.gz files that we've saved \n",
    "\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "nii_bl = np.empty((nsub, n_components), dtype='object')\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(os.path.join(sub, 'fastsrm')):\n",
    "        nii_bl[s] = np.array(sorted(glob.glob(sub + '/fastsrm/basis*gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't use a list of lists as input, unlike for other\n",
    "# nilearn functions. A single un-nested list works, however.\n",
    "can_ica_res = can_ica.fit(nii_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugo reminded me that I can use FastICA, so trying \n",
    "# that. The inputs are easier here since FastICA accepts 2D\n",
    "# arrays as input.\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Set up some parameters for the ICA\n",
    "n_components = 20\n",
    "random_state = 0\n",
    "max_iter = 5000\n",
    "tol = 0.005\n",
    "\n",
    "# Initialize the ICA model\n",
    "fast_ica = FastICA(n_components=n_components,\n",
    "                  random_state=random_state,\n",
    "                  max_iter=max_iter,\n",
    "                  tol=tol)\n",
    "\n",
    "# Transform input data using the ICA model\n",
    "spatial_map_ica = fast_ica.fit_transform(basis_lists.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output has dimensions n_components x (n_subjects * n_voxels)\n",
    "# I checked with Hugo, and he says that the output can be treated as\n",
    "# the first n_voxels of each component belong to the first subject,\n",
    "# and so on. With that assumption, let's split the output.\n",
    "\n",
    "for c in range(n_components):\n",
    "    for s, sub in enumerate(subs):\n",
    "        smap = spatial_map_ica[c, s*n_voxel:(s+1)*n_voxel]\n",
    "        nib.save(img_masker.inverse_transform(smap), \n",
    "                     os.path.join(sub, 'fastsrm', 'sica_on_fastsrm', \n",
    "                                  'sica_basis_list-' + str(c) + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second level maps from sICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules/functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nistats.reporting import make_glm_report\n",
    "\n",
    "input_folder = 'sica_on_fastsrm'\n",
    "input_file = 'sica_basis_list-'\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "nsub = len(subs)\n",
    "\n",
    "# Let's gather the files that will form the input to the second level analysis\n",
    "n_components = 20\n",
    "second_level_input = np.empty((nsub,n_components), dtype='object')\n",
    "\n",
    "sidx = 0\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        for c in range(n_components):\n",
    "            second_level_input[sidx][c] = os.path.join(sub, 'fastsrm', input_folder, \n",
    "                                                       input_file + str(c) + '.nii.gz')\n",
    "        sidx += 1\n",
    "\n",
    "# Construct a design matrix. We are including all subjects and \n",
    "# essentially finding the \"main effects\" of the contrasts performed\n",
    "# in the first level analysis\n",
    "design_matrix = pd.DataFrame([1] * len(second_level_input), columns=['intercept'])\n",
    "\n",
    "# Set up the second level analysis\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8)\n",
    "\n",
    "# Compute the contrast/main effect\n",
    "for i in range(20):\n",
    "    z_map = second_level_model.fit(list(second_level_input[:,i]), \n",
    "                                    design_matrix=design_matrix).compute_contrast(output_type='z_score')\n",
    "    report = make_glm_report(second_level_model, 'intercept')\n",
    "    report.save_as_html(os.path.join(movie_dir, 'fastsrm', input_folder, \n",
    "                                     'component-' + str(i) + '.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
