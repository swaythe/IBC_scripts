{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some global variables\n",
    "base_dir = '/volatile/sshankar/ds000003-00001/'\n",
    "task_label = '_task-rhymejudgment_'\n",
    "deriv = 'preprocess_op/'\n",
    "tr = 2 # Scan repetition time\n",
    "n_sub = 13\n",
    "# subs = [5, 6, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory for the statistical output\n",
    "from os import mkdir\n",
    "op_dir = base_dir + 'Statistics/'\n",
    "\n",
    "try:\n",
    "    mkdir(op_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/sshankar/pyp_env/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# A few more imports of import\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "from nistats.first_level_model import FirstLevelModel\n",
    "from nilearn import plotting\n",
    "from nistats.reporting import make_glm_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 13 subjects so let's go through the list and\n",
    "# start setting up subject-specific folders and files\n",
    "\n",
    "s_name = []\n",
    "data_dir = []\n",
    "deriv_dir = []\n",
    "fmri_file = []\n",
    "n_scans = []\n",
    "events_file = []\n",
    "regs = []\n",
    "dm_file = []\n",
    "contrasts_file = []\n",
    "\n",
    "for sub in range(n_sub):\n",
    "    # Create variable with subject id\n",
    "    sub_name = 'sub-' + str(sub+1).zfill(2)\n",
    "#     sub_name = 'sub-' + str(subs[sub]).zfill(2)\n",
    "    s_name.append(sub_name)\n",
    "    \n",
    "    ### INPUT FILES/DIRECTORIES ###\n",
    "    # Collect the functional file directory\n",
    "    d_dat = base_dir + sub_name + '/func/'\n",
    "    data_dir.append(d_dat)\n",
    "    \n",
    "    # Collect the derivatives file directory\n",
    "    d_deriv = base_dir + deriv + sub_name + '/func/'\n",
    "    deriv_dir.append(d_deriv)\n",
    "    \n",
    "    # We will open the derivative functional image for each subject to figure out how long  \n",
    "    # (#TR) the session was, and save that information for later\n",
    "    f_fmri = d_deriv + 'wr' + sub_name + task_label + 'bold.nii.gz'\n",
    "    fmri_file.append(f_fmri)\n",
    "    fmri_img = image.load_img(f_fmri)\n",
    "    n_scans.append(fmri_img.shape[-1])\n",
    "    \n",
    "    # Collect the names of the event files for each subject\n",
    "    events_file.append(d_dat + sub_name + task_label + 'events.tsv')\n",
    "    \n",
    "    # Finally, collect the motion parameters files\n",
    "    regs.append(d_deriv + 'rp_' + sub_name + task_label + 'bold.txt')\n",
    "\n",
    "    ### OUTPUT FILES/DIRECTORIES ###\n",
    "    # Create an output statistics directory for each subject\n",
    "    sub_op = op_dir + sub_name + '/'\n",
    "    try:\n",
    "        mkdir(sub_op)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # Files to save design matrices in\n",
    "    dm_file.append(sub_op + 'design_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the design matrices\n",
    "\n",
    "# Specify an model for the HRF\n",
    "hrf_model = 'spm + derivative'\n",
    "\n",
    "# Get the events list, TR array and nuisance regressors\n",
    "for sub in range(n_sub):\n",
    "    events = pd.read_table(events_file[sub])\n",
    "    frame_times = np.arange(n_scans[sub]) * tr\n",
    "    add_regs = pd.read_csv(regs[sub], header=None, sep='\\s+')\n",
    "    \n",
    "    # Create the design matrix\n",
    "    design_matrix = make_first_level_design_matrix(\n",
    "        frame_times,\n",
    "        events,\n",
    "        hrf_model=hrf_model,\n",
    "        add_regs=add_regs\n",
    "    )\n",
    "    # Save design matrix to file \n",
    "    design_matrix.to_csv(dm_file[sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up and run the GLM and contrasts\n",
    "\n",
    "# Initialize the first-level model\n",
    "fmri_glm = FirstLevelModel(t_r=tr, hrf_model=hrf_model)\n",
    "\n",
    "for sub in range(n_sub):\n",
    "    # Read in the design matrix from the csv file\n",
    "    dm = pd.read_csv(dm_file[sub])\n",
    "    \n",
    "    # Create the contrast matrix\n",
    "    contrast_matrix = np.eye(dm.shape[1])\n",
    "    basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(dm.columns)])\n",
    "    \n",
    "    # Set up the contrasts of interest\n",
    "    # In the rhyme judgement task, the primary contrasts of interest are:\n",
    "    # 1. The task main effects\n",
    "    # 2. Word - Pseudoword\n",
    "    # 3. Pseudoword - Word\n",
    "    contrasts = {\n",
    "        'main_effects': np.vstack((basic_contrasts['word'], basic_contrasts['pseudoword'])),\n",
    "        'word': basic_contrasts['word'],\n",
    "        'pseudoword': basic_contrasts['pseudoword'],\n",
    "        'word-pseudoword': basic_contrasts['word'] - basic_contrasts['pseudoword'],\n",
    "        'pseudoword-word': -basic_contrasts['word'] + basic_contrasts['pseudoword']\n",
    "    }\n",
    "\n",
    "    # Run the GLM and compute the contrasts\n",
    "    for contrast_id, contrast_val in contrasts.items():\n",
    "        stat_map = fmri_glm.fit(fmri_file[sub], design_matrices=dm).compute_contrast(\n",
    "            contrast_val, output_type='stat')\n",
    "      \n",
    "        # Save the contrast map to disk\n",
    "        stat_map.to_filename(op_dir + s_name[sub] + '/' + s_name[sub] + '_' + contrast_id + '_stat-map.nii.gz')\n",
    "        \n",
    "    # Set up the report \n",
    "    rhymejudgment_report = make_glm_report(fmri_glm, contrasts)\n",
    "    rhymejudgment_report.save_as_html(op_dir + s_name[sub] + '/' + 'rhymejudgement_report_first_level.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 3\n",
    "contrast_id = 'word-pseudoword'\n",
    "z_file = op_dir + s_name[sub] + '/' + s_name[sub] + '_' + contrast_id + '_z-map.nii.gz'\n",
    "plotting.plot_stat_map(z_file, display_mode='z', threshold=2, black_bg=True, title=contrast_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 6\n",
    "contrast_id = 'word-pseudoword'\n",
    "z_file = op_dir + s_name[sub] + '/' + s_name[sub] + '_' + contrast_id + '_z-map.nii.gz'\n",
    "plotting.plot_stat_map(z_file, display_mode='z', threshold=2, black_bg=True, title=contrast_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
