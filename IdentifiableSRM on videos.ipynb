{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshankar/env/fastsrm/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker, MultiNiftiMasker\n",
    "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\n",
    "from nilearn.image import new_img_like\n",
    "from fastsrm.identifiable_srm import IdentifiableFastSRM\n",
    "from nilearn import image, plotting\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import ibc_public\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask image\n",
    "_package_directory = os.path.dirname(os.path.abspath(ibc_public.__file__))\n",
    "mask_gm = nib.load(os.path.join(_package_directory, '../ibc_data', 'gm_mask_3mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task of interest\n",
    "task = 'raiders'\n",
    "\n",
    "# Any specific files that should be used for FastSRM\n",
    "if task == 'clips':\n",
    "    sessn = 3\n",
    "    filepattern = '*Trn*.nii.gz'\n",
    "else:\n",
    "    sessn = 2\n",
    "    filepattern = '*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for a previously unused atlas. \n",
    "# Else, you should have a .npy file saved from before, and you can just load it.\n",
    "# The transform() funtion takes a few minutes to run so don't run it \n",
    "# unless you absolutely need to.\n",
    "\n",
    "# Now, a bit of shape shifting to make the atlas compatible with\n",
    "# what fastsrm.reduce_data() requires.\n",
    "# 1. Add a 4th dimension to the 3D atlas. The 4th dimension will have as many\n",
    "#   elements as atlas parcesl (444, in this case)\n",
    "# 2. The 3D \"volume\" pertaining to each 4th dimension will contain 1 in the\n",
    "#   \"voxel\" for that parcel and 0 otherwise\n",
    "# 3. Apply the atlas masker set up previously to transform the new 4D atlas\n",
    "#   into 2D, with n_voxel rows and n_parcel columns,\n",
    "#   where n_voxel is the number of voxels in the transformed image matrix\n",
    "# 4. Reduce the 2D atlas matrix to 1D by using the argmax function along the\n",
    "#   column dimension. Now, the transformed atlas has n_voxel elements.\n",
    "\n",
    "atlas_loc = os.path.join('..', task, '3mm')\n",
    "if os.path.exists(os.path.join(atlas_loc, 'atlas_masked.npy')):\n",
    "    atlas = np.load(os.path.join(atlas_loc, 'atlas_masked.npy'), allow_pickle=True)\n",
    "else:\n",
    "    # Specify the atlas\n",
    "    basc444 = fetch_atlas_basc_multiscale_2015()['scale444']\n",
    "    basc_im = image.load_img(basc444).get_data()\n",
    "\n",
    "    atlas_masker = NiftiMasker(mask_img=mask_gm).fit()\n",
    "\n",
    "    if len(basc_im.shape) == 3:\n",
    "        n_components = len(np.unique(basc_im)) - 1\n",
    "        xa, ya, za = basc_im.shape\n",
    "        A = np.zeros((xa, ya, za, n_components + 1))\n",
    "        atlas = np.zeros((xa, ya, za, n_components + 1))\n",
    "        for c in np.unique(basc_im)[1:].astype(int):\n",
    "            X_ = np.copy(basc_im)\n",
    "            X_[X_ != c] = 0.\n",
    "            X_[X_ == c] = 1.\n",
    "            A[:, :, :, c] = X_\n",
    "        atlas = atlas_masker.transform(new_img_like(basc444, A))\n",
    "        atlas = np.argmax(atlas, axis=0)\n",
    "\n",
    "    # # Save the transformed atlas\n",
    "    np.save(os.path.join(atlas_loc, 'atlas_masked.npy'), atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to standardize (0 mean, 1 SD) the image files\n",
    "# and to transform them to a 2D array, as FastSRM requires\n",
    "img_masker = NiftiMasker(mask_img=mask_gm, \n",
    "                              standardize=True, \n",
    "                              smoothing_fwhm=5,\n",
    "                              detrend=True,\n",
    "                              high_pass=1./128,\n",
    "                              t_r=2.0).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now create a list of movie session files \n",
    "movie_dir = os.path.join('..', task, '3mm/')\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "nsub = 0\n",
    "\n",
    "movie_arrays = []\n",
    "\n",
    "# Number of sessions per subject\n",
    "# Different tasks have different numbers of sessions.\n",
    "# Also, all subjects might not have completed all sessions.\n",
    "if task == 'clips':\n",
    "    # For the clips task, one subject doesn't have all 4 sessions, and\n",
    "    # FastSRM requires that all subjects have the same numbers of TRs\n",
    "    sessn = 3\n",
    "else:\n",
    "    sessn = 2\n",
    "\n",
    "# Create 2D masked arrays from image data and save to file for quick and easy access\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        nsub += 1\n",
    "        sess = sorted(glob.glob(sub + '/ses*'))\n",
    "       \n",
    "        for i, ses in enumerate(sess):\n",
    "            if os.path.isdir(ses) and i < sessn:\n",
    "                if os.path.exists(os.path.join(ses,'masked_imgs_preproc.npy')):\n",
    "                    masked_imgs = np.load(os.path.join(ses, 'masked_imgs_preproc.npy'), \n",
    "                                          allow_pickle=True)\n",
    "                else:    \n",
    "                    movie_imgs = sorted(glob.glob(ses + '/' + filepattern))\n",
    "                    masked_imgs = img_masker.transform(movie_imgs)\n",
    "                    np.save(os.path.join(ses, 'masked_imgs_preproc.npy'), masked_imgs)\n",
    "\n",
    "                movie_arrays.append(masked_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the runs belonging to each subject, \n",
    "# and then create a list of lists with all subjects' data\n",
    "sub_movie = []\n",
    "# nsess = len(movie_arrays[0])\n",
    "for i in range(0, nsub*sessn, sessn):\n",
    "    part = []\n",
    "    for j in range(sessn):\n",
    "        # The inner concatenates create one list each for each session\n",
    "        # The outer concatenate creates one list with data from all runs\n",
    "        part.append(np.concatenate(movie_arrays[i+j]))\n",
    "    sub_movie.append(np.concatenate(part).T)\n",
    "#         sub_movie.append(np.concatenate((np.concatenate(movie_arrays[i]), np.concatenate(movie_arrays[i+1]))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nsub):\n",
    "    print(sub_movie[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IdentifiableFastSRM(aggregate='mean',\n",
       "                    atlas=array([333, 333, 190, ..., 112, 315, 315]),\n",
       "                    identifiability='ica', low_ram=True, n_components=20,\n",
       "                    n_iter=10, n_jobs=1, n_subjects_ica=10,\n",
       "                    temp_dir='/tmp/fastsrme74e4bea-88bf-4710-a6eb-2217ad194260',\n",
       "                    verbose='warn')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the FastSRM model with the data\n",
    "fast_srm = IdentifiableFastSRM(\n",
    "    atlas=atlas,\n",
    "    n_components=20,\n",
    "    n_jobs=1,\n",
    "    n_iter=10,\n",
    "    temp_dir='/tmp',\n",
    "    low_ram=True, \n",
    "    aggregate=\"mean\",\n",
    "    identifiability=\"ica\",\n",
    "    n_subjects_ica=nsub,)\n",
    "\n",
    "fast_srm.fit(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the shared temporal responses of subjects while watching the movie\n",
    "shared_resp = fast_srm.transform(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the shared responses look like\n",
    "fig, axs = plt.subplots(20, sharex=True, sharey=True, \n",
    "                        figsize=(10,50))\n",
    "# gridspec_kw={'hspace': 0.2}\n",
    "for i in range(len(shared_resp)):\n",
    "    axs[i].plot(shared_resp[i,:])\n",
    "    axs[i].set_title('Shared response #' + str(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the shared response vector for future use\n",
    "fastsrm_dir = os.path.join(movie_dir, 'ident_fastsrm')\n",
    "\n",
    "if not os.path.isdir(fastsrm_dir):\n",
    "    os.mkdir(fastsrm_dir)\n",
    "\n",
    "np.save(os.path.join(fastsrm_dir, 'shared_resp.npy'), shared_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the shared response figure as pdf\n",
    "fig.savefig(os.path.join(fastsrm_dir, 'shared_resp.pdf'), format='pdf', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for one subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_9.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for a different subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_5.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subject-specific spatial maps are in the parameter basis_list\n",
    "# These spatial maps have been created using all runs from all subjects\n",
    "fast_srm.basis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the basis lists to subject folders for posterity\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    srm_sub_dir = os.path.join(sub, 'ident_fastsrm')\n",
    "    if not os.path.isdir(srm_sub_dir):\n",
    "        os.mkdir(srm_sub_dir)\n",
    "    copyfile(fast_srm.basis_list[s], os.path.join(srm_sub_dir, 'basis_list.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the basis lists into their components and save them as \n",
    "# niimg-like files to use in other nistats/nilearn functions\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    bls = np.load(os.path.join(sub, 'ident_fastsrm_ica', 'basis_list.npy'))\n",
    "    for i in range(20):\n",
    "        nib.save(img_masker.inverse_transform(bls[i]), \n",
    "                 os.path.join(sub, 'ident_fastsrm_ica', 'basis_list-' + str(i).zfill(2) + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to second level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules/functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nistats.reporting import make_glm_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's gather the files that will form the input to the second level analysis\n",
    "n_components = 20\n",
    "second_level_input = np.empty((nsub,n_components), dtype='object')\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    for c in range(n_components):\n",
    "        second_level_input[s][c] = os.path.join(\n",
    "            sub, 'ident_fastsrm_ica', 'basis_list-' + str(c).zfill(2) + '.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a design matrix. We are including all subjects and \n",
    "# essentially finding the \"main effects\" of the contrasts performed\n",
    "# in the first level analysis\n",
    "design_matrix = pd.DataFrame([1] * len(second_level_input), columns=['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the second level analysis\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the contrast/main effect\n",
    "for i in range(n_components):\n",
    "    z_map = second_level_model.fit(list(second_level_input[:,i]), \n",
    "                                    design_matrix=design_matrix).compute_contrast(output_type='z_score')\n",
    "    report = make_glm_report(second_level_model, 'intercept')\n",
    "    report.save_as_html(os.path.join(movie_dir, 'ident_fastsrm_ica', 'component-' + str(i).zfill(2) + '.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some FPR correction with cluster size thresholding, after applying an uncorrected p=0.01\n",
    "thresholded_map1, threshold1 = map_threshold(z_map1, alpha=.01, height_control='fpr', cluster_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the temporal ICA on the shared responses here\n",
    "since we need to use the inverse transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Set up some parameters for the ICA\n",
    "n_components = 20\n",
    "random_state = 0\n",
    "max_iter = 5000\n",
    "tol = 0.005\n",
    "\n",
    "# Initialize the ICA model\n",
    "fast_ica = FastICA(n_components=n_components,\n",
    "                  random_state=random_state,\n",
    "                  max_iter=max_iter,\n",
    "                  tol=tol)\n",
    "\n",
    "# Transform input data using the ICA model\n",
    "shared_resp_ica = fast_ica.fit_transform(shared_resp.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the add_subjects() function to generate spatial maps\n",
    "# corresponding to the ICA components\n",
    "fast_srm.add_subjects(sub_movie, shared_resp_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_srm.basis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the basis lists to subject folders for posterity\n",
    "from shutil import copyfile\n",
    "\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "\n",
    "sidx = 10\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        copyfile(fast_srm.basis_list[sidx], \n",
    "                 os.path.join(sub, 'fastsrm', 'tica_on_fastsrm', 'tica_basis_list.npy'))\n",
    "        sidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the basis lists into their components and save them as \n",
    "# niimg-like files to use in other nistats/nilearn functions\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        bls = np.load(os.path.join(sub, 'fastsrm', 'tica_on_fastsrm', 'tica_basis_list.npy'))\n",
    "        for i in range(20):\n",
    "            nib.save(img_masker.inverse_transform(bls[i]), \n",
    "                     os.path.join(sub, 'fastsrm', 'tica_on_fastsrm', \n",
    "                                  'tica_basis_list-' + str(i).zfill(2) + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second level maps from tICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules/functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nistats.reporting import make_glm_report\n",
    "\n",
    "task = 'clips'\n",
    "movie_dir = os.path.join('..', task, '3mm')\n",
    "subs = sorted(glob.glob(movie_dir + '/sub*'))\n",
    "nsub = len(subs)\n",
    "\n",
    "# Let's gather the files that will form the input to the second level analysis\n",
    "n_components = 20\n",
    "second_level_input = np.empty((nsub,n_components), dtype='object')\n",
    "\n",
    "sidx = 0\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        for c in range(n_components):\n",
    "            second_level_input[sidx][c] = os.path.join(sub, 'fastsrm', 'tica_on_fastsrm', \n",
    "                                                       'tica_basis_list-' + str(c) + '.nii.gz')\n",
    "        sidx += 1\n",
    "\n",
    "# Construct a design matrix. We are including all subjects and \n",
    "# essentially finding the \"main effects\" of the contrasts performed\n",
    "# in the first level analysis\n",
    "design_matrix = pd.DataFrame([1] * len(second_level_input), columns=['intercept'])\n",
    "\n",
    "# Set up the second level analysis\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8)\n",
    "\n",
    "# Compute the contrast/main effect\n",
    "for i in range(20):\n",
    "    z_map = second_level_model.fit(list(second_level_input[:,i]), \n",
    "                                    design_matrix=design_matrix).compute_contrast(output_type='z_score')\n",
    "    report = make_glm_report(second_level_model, 'intercept')\n",
    "    report.save_as_html(os.path.join(movie_dir, 'fastsrm', 'tica_on_fastsrm', \n",
    "                                     'component-' + str(i).zfill(2) + '.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some FPR correction with cluster size thresholding, after applying an uncorrected p=0.01\n",
    "thresholded_map1, threshold1 = map_threshold(z_map1, alpha=.01, height_control='fpr', cluster_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
