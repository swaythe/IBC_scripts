{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshankar/env/fastsrm/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker, MultiNiftiMasker\n",
    "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\n",
    "from nilearn.image import new_img_like\n",
    "from fastsrm.fastsrm import FastSRM\n",
    "from fastsrm.identifiable_srm import IdentifiableFastSRM\n",
    "from nilearn import image, plotting\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import ibc_public\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask image\n",
    "_package_directory = os.path.dirname(os.path.abspath(ibc_public.__file__))\n",
    "mask_gm = nib.load(os.path.join(_package_directory, '../ibc_data', 'gm_mask_3mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task of interest\n",
    "task = 'raiders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for a previously unused atlas. \n",
    "# Else, you should have a .npy file saved from before, and you can just load it.\n",
    "# The transform() funtion takes a few minutes to run so don't run it \n",
    "# unless you absolutely need to.\n",
    "\n",
    "# Now, a bit of shape shifting to make the atlas compatible with\n",
    "# what fastsrm.reduce_data() requires.\n",
    "# 1. Add a 4th dimension to the 3D atlas. The 4th dimension will have as many\n",
    "#   elements as atlas parcesl (444, in this case)\n",
    "# 2. The 3D \"volume\" pertaining to each 4th dimension will contain 1 in the\n",
    "#   \"voxel\" for that parcel and 0 otherwise\n",
    "# 3. Apply the atlas masker set up previously to transform the new 4D atlas\n",
    "#   into 2D, with n_voxel rows and n_parcel columns,\n",
    "#   where n_voxel is the number of voxels in the transformed image matrix\n",
    "# 4. Reduce the 2D atlas matrix to 1D by using the argmax function along the\n",
    "#   column dimension. Now, the transformed atlas has n_voxel elements.\n",
    "\n",
    "atlas_loc = os.path.join('..', task, '3mm')\n",
    "if os.path.exists(os.path.join(atlas_loc, 'atlas_masked.npy')):\n",
    "    atlas = np.load(os.path.join(atlas_loc, 'atlas_masked.npy'), allow_pickle=True)\n",
    "else:\n",
    "    # Specify the atlas\n",
    "    basc444 = fetch_atlas_basc_multiscale_2015()['scale444']\n",
    "    basc_im = image.load_img(basc444).get_data()\n",
    "\n",
    "    atlas_masker = NiftiMasker(mask_img=mask_gm).fit()\n",
    "\n",
    "    if len(basc_im.shape) == 3:\n",
    "        n_components = len(np.unique(basc_im)) - 1\n",
    "        xa, ya, za = basc_im.shape\n",
    "        A = np.zeros((xa, ya, za, n_components + 1))\n",
    "        atlas = np.zeros((xa, ya, za, n_components + 1))\n",
    "        for c in np.unique(basc_im)[1:].astype(int):\n",
    "            X_ = np.copy(basc_im)\n",
    "            X_[X_ != c] = 0.\n",
    "            X_[X_ == c] = 1.\n",
    "            A[:, :, :, c] = X_\n",
    "        atlas = atlas_masker.transform(new_img_like(basc444, A))\n",
    "        atlas = np.argmax(atlas, axis=0)\n",
    "\n",
    "    # # Save the transformed atlas\n",
    "    np.save(os.path.join(atlas_loc, 'atlas_masked.npy'), atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a masker to standardize (0 mean, 1 SD) the image files\n",
    "# and to transform them to a 2D array, as FastSRM requires\n",
    "img_masker = MultiNiftiMasker(mask_img=mask_gm, \n",
    "                              standardize=True, \n",
    "                              smoothing_fwhm=5,\n",
    "                              detrend=True,\n",
    "                              high_pass=1./128,\n",
    "                              t_r=2.0).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any specific files that should be used for FastSRM\n",
    "if task == 'clips':\n",
    "    sessn = 3\n",
    "    filepattern = 'wrdc*Trn*run-04*.nii.gz'\n",
    "else:\n",
    "    sessn = 2\n",
    "    filepattern = 'wrdc*run-01*.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now create a list of movie session files \n",
    "movie_dir = os.path.join('..', task, '3mm/')\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "nsub = 0\n",
    "preproc_file = 'masked_imgs_preproc_run1.npy'\n",
    "\n",
    "movie_arrays = []\n",
    "\n",
    "# Number of sessions per subject\n",
    "# Different tasks have different numbers of sessions.\n",
    "# Also, all subjects might not have completed all sessions.\n",
    "if task == 'clips':\n",
    "    # For the clips task, one subject doesn't have all 4 sessions, and\n",
    "    # FastSRM requires that all subjects have the same numbers of TRs\n",
    "    sessn = 3\n",
    "else:\n",
    "    sessn = 2\n",
    "\n",
    "# Create 2D masked arrays from image data and save to file for quick and easy access\n",
    "for s, sub in enumerate(subs):\n",
    "    if os.path.isdir(sub):\n",
    "        nsub += 1\n",
    "        sess = sorted(glob.glob(sub + '/ses*'))\n",
    "        ses = sess[1]\n",
    "       \n",
    "        if os.path.exists(os.path.join(ses, preproc_file)):\n",
    "            masked_imgs = np.load(os.path.join(ses, preproc_file), \n",
    "                                  allow_pickle=True)\n",
    "        else:    \n",
    "            movie_imgs = sorted(glob.glob(ses + '/' + filepattern))\n",
    "            masked_imgs = img_masker.transform(movie_imgs)\n",
    "            np.save(os.path.join(ses, preproc_file), masked_imgs)\n",
    "\n",
    "        movie_arrays.append(masked_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n",
      "(314, 46448)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(subs)):\n",
    "    for j in range(len(movie_arrays[i])):\n",
    "        print(movie_arrays[i][j].shape)\n",
    "# movie_arrays[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all subjects' data\n",
    "sub_movie = []\n",
    "\n",
    "for i in range(0, nsub):\n",
    "    sub_movie.append(np.concatenate(movie_arrays[i]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the FastSRM model with the data\n",
    "fast_srm = IdentifiableFastSRM(\n",
    "    atlas=atlas,\n",
    "    n_components=20,\n",
    "    n_jobs=1,\n",
    "    n_iter=1000,\n",
    "    n_iter_reduced=1000,\n",
    "    temp_dir='/tmp',\n",
    "    low_ram=True, \n",
    "    aggregate=\"mean\",\n",
    "    identifiability='decorr'\n",
    ")\n",
    "fast_srm.fit(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the shared temporal responses of subjects while watching the movie\n",
    "shared_resp = fast_srm.transform(sub_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the shared response vector for future use\n",
    "fastsrm_dir = os.path.join(movie_dir, 'fastsrm', 'single_run')\n",
    "if not os.path.isdir(fastsrm_dir):\n",
    "    os.mkdir(fastsrm_dir)\n",
    "\n",
    "np.save(os.path.join(fastsrm_dir, 'shared_resp_run12_niter1000.npy'), shared_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_resp = scale(shared_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaled_resp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(fastsrm_dir, 'scaled_resp_run1.npy'), scaled_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "norm_resp = normalize(shared_resp)\n",
    "plt.plot(norm_resp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(fastsrm_dir, 'norm_resp_run1.npy'), norm_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastsrm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the shared responses look like\n",
    "fig, axs = plt.subplots(20, sharex=True, sharey=True, \n",
    "                        figsize=(10,50))\n",
    "# gridspec_kw={'hspace': 0.2}\n",
    "for i in range(len(shared_resp)):\n",
    "    axs[i].plot(shared_resp[i,:])\n",
    "    axs[i].set_title('Shared response #' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(fastsrm_dir, 'shared_resp_run12_niter1000.pdf'), format='pdf', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for one subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_9.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are what the spatial maps look like, for a different subject\n",
    "bl1 = np.load('/tmp/fastsrm7cb4ce8e-1d76-4615-9c17-5a3cf6c57b16/basis_5.npy', allow_pickle=True)\n",
    "inv_mask_bl1 = img_masker.inverse_transform(bl1)\n",
    "\n",
    "for i in range(len(shared_resp)):\n",
    "    plotting.plot_epi(inv_mask_bl1.slicer[...,i], draw_cross=False, \n",
    "                     cut_coords=7, display_mode='z', black_bg=True, cmap=plotting.cm.blue_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subject-specific spatial maps are in the parameter basis_list\n",
    "# These spatial maps have been created using all runs from all subjects\n",
    "fast_srm.basis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the basis lists to subject folders for posterity\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    srm_sub_dir = os.path.join(sub, 'fastsrm')\n",
    "    if not os.path.isdir(srm_sub_dir):\n",
    "        os.mkdir(srm_sub_dir)\n",
    "    copyfile(fast_srm.basis_list[s], os.path.join(srm_sub_dir, 'basis_list_run3.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the basis lists into their components and save them as \n",
    "# niimg-like files to use in other nistats/nilearn functions\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    bls = np.load(os.path.join(sub, 'fastsrm', 'basis_list.npy'))\n",
    "    for i in range(20):\n",
    "        nib.save(img_masker.inverse_transform(bls[i]), \n",
    "                 os.path.join(sub, 'fastsrm', 'basis_list-' + str(i).zfill(2) + '_run3.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to second level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules/functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nistats.reporting import make_glm_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's gather the files that will form the input to the second level analysis\n",
    "n_components = 20\n",
    "second_level_input = np.empty((nsub,n_components), dtype='object')\n",
    "subs = sorted(glob.glob(movie_dir + 'sub*'))\n",
    "\n",
    "for s, sub in enumerate(subs):\n",
    "    for c in range(n_components):\n",
    "        second_level_input[s][c] = os.path.join(\n",
    "            sub, 'fastsrm', 'basis_list-' + str(c).zfill(2) + '_run3.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a design matrix. We are including all subjects and \n",
    "# essentially finding the \"main effects\" of the contrasts performed\n",
    "# in the first level analysis\n",
    "design_matrix = pd.DataFrame([1] * len(second_level_input), columns=['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the second level analysis\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the contrast/main effect\n",
    "for i in range(20):\n",
    "    z_map = second_level_model.fit(list(second_level_input[:,i]), \n",
    "                                    design_matrix=design_matrix).compute_contrast(output_type='z_score')\n",
    "    nib.save(new_img_like(mask_gm, z_map.get_fdata()), \n",
    "             os.path.join(movie_dir, 'fastsrm', 'component-' + str(i).zfill(2) + '_run3.nii.gz'))\n",
    "    #report = make_glm_report(second_level_model, 'intercept')\n",
    "    #report.save_as_html(os.path.join(movie_dir, 'fastsrm', 'reduced-back', 'component-' + \n",
    "    #                                 str(i).zfill(2) + '.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
